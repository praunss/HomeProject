{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone - Financial Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import fundamental packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "#import pandas_datareader.data as web\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import seaborn as sn\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from matplotlib import pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "from matplotlib.pyplot import savefig\n",
    "import time\n",
    "from scipy.misc import imresize\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get financial data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this section if you want to download the data yourself. It is not compulsary, as the data is stored as \"Data-5year-2012-2017.csv\", and loaded in the relevant sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Financial data is downloaded via the quandl API (https://www.quandl.com/)\n",
    "    - Time interval: 2012-01-01 -- 2017-01-01\n",
    "    - Data type: Adj. Close from NASDAQ 100 (Here: Only 88 companies, 12 had too many missing values)\n",
    "- .csv file is saved on HDD for later processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"U5cJSsnv4Ad7UUnHNGu8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nasdaq 100 Company list\n",
    "companies = [\"WIKI/ATVI.11\",\"WIKI/ADBE.11\",\"WIKI/AKAM.11\",\"WIKI/ALXN.11\",\"WIKI/GOOGL.11\",\"WIKI/AMZN.11\",\"WIKI/AAL.11\",\"WIKI/AMGN.11\",\"WIKI/ADI.11\",\"WIKI/AAPL.11\",\"WIKI/AMAT.11\",\"WIKI/ADSK.11\",\"WIKI/ADP.11\",\"WIKI/BIDU.11\",\"WIKI/BIIB.11\",\"WIKI/BMRN.11\",\"WIKI/CA.11\",\"WIKI/CELG.11\",\"WIKI/CERN.11\",\"WIKI/CHKP.11\",\"WIKI/CTAS.11\",\"WIKI/CSCO.11\",\"WIKI/CTXS.11\",\"WIKI/CTSH.11\",\"WIKI/CMCSA.11\",\"WIKI/COST.11\",\"WIKI/CSX.11\",\"WIKI/XRAY.11\",\"WIKI/DISCA.11\",\"WIKI/DISH.11\",\"WIKI/DLTR.11\",\"WIKI/EBAY.11\",\"WIKI/EA.11\",\"WIKI/EXPE.11\",\"WIKI/ESRX.11\",\"WIKI/FAST.11\",\"WIKI/FISV.11\",\"WIKI/GILD.11\",\"WIKI/HAS.11\",\"WIKI/HSIC.11\",\"WIKI/HOLX.11\",\"WIKI/IDXX.11\",\"WIKI/ILMN.11\",\"WIKI/INCY.11\",\"WIKI/INTC.11\",\"WIKI/INTU.11\",\"WIKI/ISRG.11\",\"WIKI/JBHT.11\",\"WIKI/KLAC.11\",\"WIKI/LRCX.11\",\"WIKI/LBTYA.11\",\"WIKI/MAR.11\",\"WIKI/MAT.11\",\"WIKI/MXIM.11\",\"WIKI/MCHP.11\",\"WIKI/MU.11\",\"WIKI/MDLZ.11\",\"WIKI/MSFT.11\",\"WIKI/MNST.11\",\"WIKI/MYL.11\",\"WIKI/NFLX.11\",\"WIKI/NVDA.11\",\"WIKI/ORLY.11\",\"WIKI/PCAR.11\",\"WIKI/PAYX.11\",\"WIKI/PCLN.11\",\"WIKI/QCOM.11\",\"WIKI/REGN.11\",\"WIKI/ROST.11\",\"WIKI/STX.11\",\"WIKI/SIRI.11\",\"WIKI/SWKS.11\",\"WIKI/SBUX.11\",\"WIKI/SYMC.11\",\"WIKI/TSLA.11\",\"WIKI/TXN.11\",\"WIKI/TSCO.11\",\"WIKI/TMUS.11\",\"WIKI/FOX.11\",\"WIKI/ULTA.11\",\"WIKI/VRSK.11\",\"WIKI/VRTX.11\",\"WIKI/VIAB.11\",\"WIKI/VOD.11\",\"WIKI/WBA.11\",\"WIKI/WDC.11\",\"WIKI/WYNN.11\",\"WIKI/XLNX.11\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.14187097549438\n"
     ]
    }
   ],
   "source": [
    "#Download via API\n",
    "tickerstart = time.time()\n",
    "mydata = quandl.get(companies, start_date=\"2012-01-01\", end_date=\"2017-01-01\")\n",
    "tickerend = time.time()\n",
    "print(tickerend-tickerstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as csv\n",
    "mydata.to_csv(\"Data-5year-2012-2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tensor Generation for Neural Networks, from complete dataframe that has been generated with quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the 5 year dataframe that has been downloaded via quandl will be transformed into input images and targets. This section has to be run in order to supply the ANNs with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the tensor is created\n",
    "- Normalize entire 5 year dataframe for each company seperately\n",
    "- Extract last 250 available data points (approx. 1 year of data) => 1 image \n",
    "- Shift one day for 5 years (2012-2017) -> ~250 images per year, Approximation:(5 * 250)-30 = 1220 images\n",
    "- Final output: np array with dimensions: 1220 x 88 x 250 (1220 images x 88 companies x 250 timepoints in image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and PCA for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata=pd.read_csv(\"Data-5year-2012-2017.csv\")#,index_col=\"Date\")\n",
    "mydata[['Date']] = mydata[['Date']].apply(pd.to_datetime, errors='ignore')\n",
    "mydata=mydata.set_index(mydata[\"Date\"])\n",
    "mydata = mydata.drop(\"Date\",axis=1)\n",
    "\n",
    "preds = np.load(\"PCAForSorting.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WIKI/ATVI - Adj. Close</th>\n",
       "      <th>WIKI/ADBE - Adj. Close</th>\n",
       "      <th>WIKI/AKAM - Adj. Close</th>\n",
       "      <th>WIKI/ALXN - Adj. Close</th>\n",
       "      <th>WIKI/GOOGL - Adj. Close</th>\n",
       "      <th>WIKI/AMZN - Adj. Close</th>\n",
       "      <th>WIKI/AAL - Adj. Close</th>\n",
       "      <th>WIKI/AMGN - Adj. Close</th>\n",
       "      <th>WIKI/ADI - Adj. Close</th>\n",
       "      <th>WIKI/AAPL - Adj. Close</th>\n",
       "      <th>...</th>\n",
       "      <th>WIKI/FOX - Adj. Close</th>\n",
       "      <th>WIKI/ULTA - Adj. Close</th>\n",
       "      <th>WIKI/VRSK - Adj. Close</th>\n",
       "      <th>WIKI/VRTX - Adj. Close</th>\n",
       "      <th>WIKI/VIAB - Adj. Close</th>\n",
       "      <th>WIKI/VOD - Adj. Close</th>\n",
       "      <th>WIKI/WBA - Adj. Close</th>\n",
       "      <th>WIKI/WDC - Adj. Close</th>\n",
       "      <th>WIKI/WYNN - Adj. Close</th>\n",
       "      <th>WIKI/XLNX - Adj. Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>11.477656</td>\n",
       "      <td>28.57</td>\n",
       "      <td>32.93</td>\n",
       "      <td>70.57</td>\n",
       "      <td>333.735209</td>\n",
       "      <td>179.03</td>\n",
       "      <td>13.303512</td>\n",
       "      <td>56.676913</td>\n",
       "      <td>30.734273</td>\n",
       "      <td>52.848787</td>\n",
       "      <td>...</td>\n",
       "      <td>15.59802</td>\n",
       "      <td>63.384438</td>\n",
       "      <td>39.36</td>\n",
       "      <td>32.23</td>\n",
       "      <td>40.245928</td>\n",
       "      <td>26.898992</td>\n",
       "      <td>29.271975</td>\n",
       "      <td>27.306007</td>\n",
       "      <td>91.264785</td>\n",
       "      <td>28.03994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            WIKI/ATVI - Adj. Close  WIKI/ADBE - Adj. Close  \\\n",
       "Date                                                         \n",
       "2012-01-03               11.477656                   28.57   \n",
       "\n",
       "            WIKI/AKAM - Adj. Close  WIKI/ALXN - Adj. Close  \\\n",
       "Date                                                         \n",
       "2012-01-03                   32.93                   70.57   \n",
       "\n",
       "            WIKI/GOOGL - Adj. Close  WIKI/AMZN - Adj. Close  \\\n",
       "Date                                                          \n",
       "2012-01-03               333.735209                  179.03   \n",
       "\n",
       "            WIKI/AAL - Adj. Close  WIKI/AMGN - Adj. Close  \\\n",
       "Date                                                        \n",
       "2012-01-03              13.303512               56.676913   \n",
       "\n",
       "            WIKI/ADI - Adj. Close  WIKI/AAPL - Adj. Close  \\\n",
       "Date                                                        \n",
       "2012-01-03              30.734273               52.848787   \n",
       "\n",
       "                     ...            WIKI/FOX - Adj. Close  \\\n",
       "Date                 ...                                    \n",
       "2012-01-03           ...                         15.59802   \n",
       "\n",
       "            WIKI/ULTA - Adj. Close  WIKI/VRSK - Adj. Close  \\\n",
       "Date                                                         \n",
       "2012-01-03               63.384438                   39.36   \n",
       "\n",
       "            WIKI/VRTX - Adj. Close  WIKI/VIAB - Adj. Close  \\\n",
       "Date                                                         \n",
       "2012-01-03                   32.23               40.245928   \n",
       "\n",
       "            WIKI/VOD - Adj. Close  WIKI/WBA - Adj. Close  \\\n",
       "Date                                                       \n",
       "2012-01-03              26.898992              29.271975   \n",
       "\n",
       "            WIKI/WDC - Adj. Close  WIKI/WYNN - Adj. Close  \\\n",
       "Date                                                        \n",
       "2012-01-03              27.306007               91.264785   \n",
       "\n",
       "            WIKI/XLNX - Adj. Close  \n",
       "Date                                \n",
       "2012-01-03                28.03994  \n",
       "\n",
       "[1 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- toPredictIndex: First Day of target\n",
    "- PredictionTimepoints: number of datapoints for NN input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228\n"
     ]
    }
   ],
   "source": [
    "# Number of companies (here: 88)\n",
    "NumberofCompanies = 88\n",
    "#Define starting point for target and number of timepoints that are used as input (org: 250, 250)\n",
    "PredictionTimepoints = 30\n",
    "FirstIndex = PredictionTimepoints\n",
    "\n",
    "MaxPoints = mydata.shape[0]-FirstIndex\n",
    "print(MaxPoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data preparation for ANNs:\n",
    "- In the next cell , inputs and targets are created for the NNs (specify with/without prior normalization, MLP/CNN, custom CNN/transfer learning CNN, stock prediction absolute/percent)\n",
    "- Details: For all companies create input vector of past stock prices and output vector of the next day.\n",
    "- Note: Three channel images are requiredfor transfer learning (here:Xception)! Solution: all 3 channels contain\n",
    "the same pixels\n",
    "\n",
    "Output: Complete input and output for multivariate in and output (MLP type 2 and CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP = True# False => CNN\n",
    "normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 30, 88)\n",
      "(1228, 88)\n"
     ]
    }
   ],
   "source": [
    "# create np array for Data Collection\n",
    "DataCollection = np.empty([1,PredictionTimepoints,NumberofCompanies])\n",
    "# Create np array for Target Collection\n",
    "TargetCollection = np.empty([1,NumberofCompanies])\n",
    "\n",
    "# Create copy of data frame for handling\n",
    "mydataPP = mydata.copy(deep=True)\n",
    "# Set StartIndex to FirstIndex\n",
    "toPredictIndex = FirstIndex\n",
    "\n",
    "#Normalization if required\n",
    "if (normalization==True):\n",
    "    mydataNP = mydata.values\n",
    "    scaler = MinMaxScaler()  \n",
    "    mydataNormalizedNP = scaler.fit_transform(mydataNP)\n",
    "    mydataPP = pd.DataFrame(mydataNormalizedNP)\n",
    "\n",
    "#FIRST define target day, THEN extract image of past data\n",
    "\n",
    "for i in range(MaxPoints):\n",
    "    \n",
    "    #START CREATE OUTPUT VECTORS\n",
    "    \n",
    "    PredictTemp = mydataPP.iloc[toPredictIndex]\n",
    "   \n",
    "    arrayPredtemp = np.array(PredictTemp, np.float32)[newaxis,:]\n",
    "    TargetCollection = np.append(TargetCollection, arrayPredtemp, axis=0)    \n",
    "    \n",
    "    \n",
    "    #START CREATE INPUT VECTORS (IMAGES)\n",
    "    end = toPredictIndex # e.g. first = 250\n",
    "    start = end  - PredictionTimepoints # e.g. first = 0\n",
    "     \n",
    "    AdjCloseTemp = mydataPP.iloc[start : end] # e.g. 0 - 249 inclusive, as last index is not sliced\n",
    "    \n",
    "    #Ordering for CNN\n",
    "    if (MLP==False):\n",
    "        arrayTemp = np.flip(np.transpose(np.array(AdjCloseTemp, np.float32)[:, :]),axis=1)\n",
    "        AdjCloseTemp = pd.DataFrame(arrayTemp)\n",
    "        AdjCloseTemp[\"cluster\"] = preds\n",
    "        AdjCloseTemp = AdjCloseTemp.sort_values(\"cluster\")\n",
    "        AdjCloseTemp = AdjCloseTemp.drop('cluster', 1)\n",
    "        arrayTemp = np.transpose(np.flip(AdjCloseTemp.values,axis=1))\n",
    "        AdjCloseTemp = pd.DataFrame(arrayTemp)\n",
    "        \n",
    "    AdjCloseTemp_Array = AdjCloseTemp.values\n",
    "    \n",
    "\n",
    "    arrayAdjClosedTemp = np.array(AdjCloseTemp_Array, np.float32)[newaxis, :,:]\n",
    "    DataCollection = np.append(DataCollection, arrayAdjClosedTemp, axis=0)\n",
    "    \n",
    "    #END CREATE IMAGES\n",
    "    \n",
    "    toPredictIndex += 1\n",
    "\n",
    "   \n",
    "DataCollection = DataCollection[1:DataCollection.shape[0],:,:]\n",
    "TargetCollection = TargetCollection[1:TargetCollection.shape[0],:]\n",
    "\n",
    "#For CNN reshape is required\n",
    "if (MLP==False):\n",
    "    DataCollection  = DataCollection.reshape(DataCollection.shape[0], DataCollection.shape[1], DataCollection.shape[2], 1)\n",
    "    \n",
    "print(DataCollection.shape)\n",
    "print(TargetCollection.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MLP type 2 Data Splitting:__Train, test , validation split for MLP type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of Training samples (70 %), Validation and Testsamples\n",
    "TrainingSamples = int(MaxPoints * 0.7)\n",
    "ValidationSamples = int((MaxPoints-TrainingSamples)/2)\n",
    "TestSamples = MaxPoints - TrainingSamples - ValidationSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(859, 30, 88)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(DataCollection[:TrainingSamples,:])\n",
    "y_train = np.copy(TargetCollection[:TrainingSamples,:])\n",
    "X_valid = np.copy(DataCollection[TrainingSamples-1:TrainingSamples+ValidationSamples,:])\n",
    "y_valid = np.copy(TargetCollection[TrainingSamples-1:TrainingSamples+ValidationSamples,:])\n",
    "X_test = np.copy(DataCollection[TrainingSamples+ValidationSamples-1:,:])\n",
    "y_test = np.copy(TargetCollection[TrainingSamples+ValidationSamples-1:,:])\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural Network Training and scoring (Keras models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP type 2:for multi company in and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MLP_B2():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(PredictionTimepoints, NumberofCompanies)))\n",
    "   # model.add(Dense(5000, activation='relu'))\n",
    "    model.add(Dense(2000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(88))\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"adamax\", metrics=['mse'])\n",
    "    \n",
    "    #if you want to load pretrained weights, uncomment next line\n",
    "   # model.load_weights('saved_models/weights.best.from_scratch_MLP_multi_norm.hdf5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 859 samples, validate on 185 samples\n",
      "Epoch 1/10000\n",
      "859/859 [==============================] - 2s 2ms/step - loss: 6.9176 - mean_squared_error: 6.9176 - val_loss: 0.9016 - val_mean_squared_error: 0.9016\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.90161, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 2/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.4186 - mean_squared_error: 0.4186 - val_loss: 0.3336 - val_mean_squared_error: 0.3336\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.90161 to 0.33360, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 3/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.1410 - mean_squared_error: 0.1410 - val_loss: 0.2249 - val_mean_squared_error: 0.2249\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33360 to 0.22494, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 4/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0944 - mean_squared_error: 0.0944 - val_loss: 0.1485 - val_mean_squared_error: 0.1485\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22494 to 0.14846, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 5/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0760 - mean_squared_error: 0.0760 - val_loss: 0.1079 - val_mean_squared_error: 0.1079\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14846 to 0.10790, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 6/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0604 - mean_squared_error: 0.0604 - val_loss: 0.0979 - val_mean_squared_error: 0.0979\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10790 to 0.09788, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 7/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0510 - mean_squared_error: 0.0510 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09788 to 0.08963, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 8/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0448 - mean_squared_error: 0.0448 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08963 to 0.07452, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 9/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0403 - mean_squared_error: 0.0403 - val_loss: 0.0698 - val_mean_squared_error: 0.0698\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07452 to 0.06983, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 10/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0700 - val_mean_squared_error: 0.0700\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06983\n",
      "Epoch 11/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0681 - val_mean_squared_error: 0.0681\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.06983 to 0.06807, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 12/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0648 - val_mean_squared_error: 0.0648\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.06807 to 0.06479, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 13/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0624 - val_mean_squared_error: 0.0624\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06479 to 0.06237, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 14/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0275 - mean_squared_error: 0.0275 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06237 to 0.06169, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 15/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0622 - val_mean_squared_error: 0.0622\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06169\n",
      "Epoch 16/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0636 - val_mean_squared_error: 0.0636\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06169\n",
      "Epoch 17/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0648 - val_mean_squared_error: 0.0648\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06169\n",
      "Epoch 18/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0641 - val_mean_squared_error: 0.0641\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06169\n",
      "Epoch 19/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0630 - val_mean_squared_error: 0.0630\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06169\n",
      "Epoch 20/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0626 - val_mean_squared_error: 0.0626\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06169\n",
      "Epoch 21/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0626 - val_mean_squared_error: 0.0626\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06169\n",
      "Epoch 22/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0629 - val_mean_squared_error: 0.0629\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06169\n",
      "Epoch 23/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0623 - val_mean_squared_error: 0.0623\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06169\n",
      "Epoch 24/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0614 - val_mean_squared_error: 0.0614\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06169 to 0.06145, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 25/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06145 to 0.06125, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 26/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0615 - val_mean_squared_error: 0.0615\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06125\n",
      "Epoch 27/10000\n",
      "859/859 [==============================] - 2s 2ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0618 - val_mean_squared_error: 0.0618\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06125\n",
      "Epoch 28/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0620 - val_mean_squared_error: 0.0620\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06125\n",
      "Epoch 29/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0619 - val_mean_squared_error: 0.0619\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06125\n",
      "Epoch 30/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0615 - val_mean_squared_error: 0.0615\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06125\n",
      "Epoch 31/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0610 - val_mean_squared_error: 0.0610\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.06125 to 0.06105, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 32/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0611 - val_mean_squared_error: 0.0611\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06105\n",
      "Epoch 33/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0620 - val_mean_squared_error: 0.0620\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06105\n",
      "Epoch 34/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06105\n",
      "Epoch 35/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06105\n",
      "Epoch 36/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0618 - val_mean_squared_error: 0.0618\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06105\n",
      "Epoch 37/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0620 - val_mean_squared_error: 0.0620\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06105\n",
      "Epoch 38/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0611 - val_mean_squared_error: 0.0611\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06105\n",
      "Epoch 39/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0612 - val_mean_squared_error: 0.0612\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06105\n",
      "Epoch 40/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0620 - val_mean_squared_error: 0.0620\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06105\n",
      "Epoch 41/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0629 - val_mean_squared_error: 0.0629\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06105\n",
      "Epoch 42/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0626 - val_mean_squared_error: 0.0626\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06105\n",
      "Epoch 43/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0621 - val_mean_squared_error: 0.0621\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06105\n",
      "Epoch 44/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0623 - val_mean_squared_error: 0.0623\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06105\n",
      "Epoch 45/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0614 - val_mean_squared_error: 0.0614\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.06105\n",
      "Epoch 46/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0603 - val_mean_squared_error: 0.0603\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.06105 to 0.06033, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 47/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0607 - val_mean_squared_error: 0.0607\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06033\n",
      "Epoch 48/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06033\n",
      "Epoch 49/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0597 - val_mean_squared_error: 0.0597\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.06033 to 0.05967, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 50/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.05967 to 0.05876, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 51/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.05876 to 0.05816, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 52/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.05816\n",
      "Epoch 53/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.05816\n",
      "Epoch 54/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0570 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.05816 to 0.05695, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 55/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0558 - val_mean_squared_error: 0.0558\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.05695 to 0.05580, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 56/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0550 - val_mean_squared_error: 0.0550\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.05580 to 0.05504, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 57/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0554 - val_mean_squared_error: 0.0554\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.05504\n",
      "Epoch 58/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0551 - val_mean_squared_error: 0.0551\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.05504\n",
      "Epoch 59/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.05504 to 0.05441, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 60/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.05441 to 0.05361, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 61/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.05361\n",
      "Epoch 62/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0547 - val_mean_squared_error: 0.0547\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.05361\n",
      "Epoch 63/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0545 - val_mean_squared_error: 0.0545\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.05361\n",
      "Epoch 64/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.05361\n",
      "Epoch 65/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.05361 to 0.05344, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 66/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.05344\n",
      "Epoch 67/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.05344 to 0.05228, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 68/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.05228 to 0.05140, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 69/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0517 - val_mean_squared_error: 0.0517\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05140\n",
      "Epoch 70/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.05140\n",
      "Epoch 71/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05140\n",
      "Epoch 72/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.05140 to 0.05136, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 73/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05136\n",
      "Epoch 74/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05136\n",
      "Epoch 75/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05136\n",
      "Epoch 76/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0524 - val_mean_squared_error: 0.0524\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05136\n",
      "Epoch 77/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05136\n",
      "Epoch 78/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0519 - val_mean_squared_error: 0.0519\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05136\n",
      "Epoch 79/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05136\n",
      "Epoch 80/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.05136\n",
      "Epoch 81/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05136\n",
      "Epoch 82/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0519 - val_mean_squared_error: 0.0519\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05136\n",
      "Epoch 83/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05136 to 0.05106, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 84/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05106\n",
      "Epoch 85/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05106\n",
      "Epoch 86/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05106\n",
      "Epoch 87/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05106\n",
      "Epoch 88/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05106\n",
      "Epoch 89/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05106\n",
      "Epoch 90/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0505 - val_mean_squared_error: 0.0505\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05106 to 0.05053, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 91/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05053 to 0.05034, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 92/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05034\n",
      "Epoch 93/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05034\n",
      "Epoch 94/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0517 - val_mean_squared_error: 0.0517\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05034\n",
      "Epoch 95/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0525 - val_mean_squared_error: 0.0525\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05034\n",
      "Epoch 96/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05034\n",
      "Epoch 97/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05034\n",
      "Epoch 98/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05034\n",
      "Epoch 99/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05034\n",
      "Epoch 100/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05034\n",
      "Epoch 101/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05034\n",
      "Epoch 102/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05034\n",
      "Epoch 103/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05034\n",
      "Epoch 104/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05034\n",
      "Epoch 105/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.05034\n",
      "Epoch 106/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05034\n",
      "Epoch 107/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05034\n",
      "Epoch 108/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05034\n",
      "Epoch 109/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05034\n",
      "Epoch 110/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05034\n",
      "Epoch 111/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.05034\n",
      "Epoch 112/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05034\n",
      "Epoch 113/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.05034\n",
      "Epoch 114/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05034\n",
      "Epoch 115/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.05034\n",
      "Epoch 116/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.05034\n",
      "Epoch 117/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.05034\n",
      "Epoch 118/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05034\n",
      "Epoch 119/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05034\n",
      "Epoch 120/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05034\n",
      "Epoch 121/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05034\n",
      "Epoch 122/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05034\n",
      "Epoch 123/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0508 - val_mean_squared_error: 0.0508\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05034\n",
      "Epoch 124/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.05034 to 0.05021, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 125/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.05021\n",
      "Epoch 126/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05021\n",
      "Epoch 127/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05021\n",
      "Epoch 128/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05021\n",
      "Epoch 129/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05021\n",
      "Epoch 130/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.05021 to 0.04848, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 131/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04848\n",
      "Epoch 132/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04848\n",
      "Epoch 133/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04848\n",
      "Epoch 134/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.04848 to 0.04770, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 135/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0517 - val_mean_squared_error: 0.0517\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04770\n",
      "Epoch 136/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04770\n",
      "Epoch 137/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.04770 to 0.04688, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 138/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04688\n",
      "Epoch 139/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04688\n",
      "Epoch 140/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04688\n",
      "Epoch 141/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.04688 to 0.04666, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 142/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04666\n",
      "Epoch 143/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04666\n",
      "Epoch 144/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.04666\n",
      "Epoch 145/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04666\n",
      "Epoch 146/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04666\n",
      "Epoch 147/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04666\n",
      "Epoch 148/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04666\n",
      "Epoch 149/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04666\n",
      "Epoch 150/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04666\n",
      "Epoch 151/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.04666\n",
      "Epoch 152/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.04666\n",
      "Epoch 153/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04666\n",
      "Epoch 154/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04666\n",
      "Epoch 155/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.04666\n",
      "Epoch 156/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.04666\n",
      "Epoch 157/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04666\n",
      "Epoch 158/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0512 - val_mean_squared_error: 0.0512\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04666\n",
      "Epoch 159/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.04666 to 0.04627, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 160/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.04627\n",
      "Epoch 161/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.04627\n",
      "Epoch 162/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04627\n",
      "Epoch 163/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.04627 to 0.04566, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 164/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.04566\n",
      "Epoch 165/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.04566\n",
      "Epoch 166/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04566\n",
      "Epoch 167/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.04566\n",
      "Epoch 168/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04566\n",
      "Epoch 169/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.04566\n",
      "Epoch 170/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04566\n",
      "Epoch 171/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04566\n",
      "Epoch 172/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.04566\n",
      "Epoch 173/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.04566\n",
      "Epoch 174/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.04566\n",
      "Epoch 175/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.04566\n",
      "Epoch 176/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.04566\n",
      "Epoch 177/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.04566\n",
      "Epoch 178/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.04566\n",
      "Epoch 179/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04566\n",
      "Epoch 180/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04566\n",
      "Epoch 181/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.04566\n",
      "Epoch 182/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04566\n",
      "Epoch 183/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.04566\n",
      "Epoch 184/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.04566\n",
      "Epoch 185/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.04566 to 0.04548, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 186/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.04548\n",
      "Epoch 187/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04548\n",
      "Epoch 188/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04548\n",
      "Epoch 189/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.04548 to 0.04527, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 190/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04527\n",
      "Epoch 191/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.04527\n",
      "Epoch 192/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.04527\n",
      "Epoch 193/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.04527\n",
      "Epoch 194/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04527\n",
      "Epoch 195/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04527\n",
      "Epoch 196/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.04527\n",
      "Epoch 197/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.04527\n",
      "Epoch 198/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.04527\n",
      "Epoch 199/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.04527\n",
      "Epoch 200/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.04527\n",
      "Epoch 201/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.04527\n",
      "Epoch 202/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.04527\n",
      "Epoch 203/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.04527\n",
      "Epoch 204/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.04527\n",
      "Epoch 205/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.04527\n",
      "Epoch 206/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.04527\n",
      "Epoch 207/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.04527\n",
      "Epoch 208/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.04527\n",
      "Epoch 209/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.04527\n",
      "Epoch 210/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.04527 to 0.04503, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 211/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.04503\n",
      "Epoch 212/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.04503\n",
      "Epoch 213/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.04503\n",
      "Epoch 214/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.04503\n",
      "Epoch 215/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.04503\n",
      "Epoch 216/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.04503\n",
      "Epoch 217/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.04503\n",
      "Epoch 218/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.04503\n",
      "Epoch 219/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.04503\n",
      "Epoch 220/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.04503 to 0.04496, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 221/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.04496\n",
      "Epoch 222/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.04496\n",
      "Epoch 223/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.04496\n",
      "Epoch 224/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.04496 to 0.04478, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 225/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.04478\n",
      "Epoch 226/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.04478\n",
      "Epoch 227/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.04478 to 0.04387, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 228/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.04387\n",
      "Epoch 229/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.04387\n",
      "Epoch 230/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.04387\n",
      "Epoch 231/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.04387 to 0.04309, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 232/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.04309\n",
      "Epoch 233/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.04309\n",
      "Epoch 234/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.04309 to 0.04232, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 235/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.04232\n",
      "Epoch 236/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.04232\n",
      "Epoch 237/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.04232\n",
      "Epoch 238/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.04232\n",
      "Epoch 239/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.04232\n",
      "Epoch 240/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.04232\n",
      "Epoch 241/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.04232\n",
      "Epoch 242/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.04232\n",
      "Epoch 243/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.04232\n",
      "Epoch 244/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.04232\n",
      "Epoch 245/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.04232\n",
      "Epoch 246/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.04232\n",
      "Epoch 247/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.04232\n",
      "Epoch 248/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.04232\n",
      "Epoch 249/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.04232\n",
      "Epoch 250/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.04232\n",
      "Epoch 251/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.04232\n",
      "Epoch 252/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.04232\n",
      "Epoch 253/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.04232\n",
      "Epoch 254/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.04232\n",
      "Epoch 255/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.04232\n",
      "Epoch 256/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.04232 to 0.04134, saving model to saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints30.hdf5\n",
      "Epoch 257/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.04134\n",
      "Epoch 258/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.04134\n",
      "Epoch 259/10000\n",
      "859/859 [==============================] - 1s 1ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.04134\n",
      "Epoch 260/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.04134\n",
      "Epoch 261/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.04134\n",
      "Epoch 262/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.04134\n",
      "Epoch 263/10000\n",
      "859/859 [==============================] - 1s 2ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0415 - val_mean_squared_error: 0.0415\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.04134\n",
      "Epoch 264/10000\n",
      "705/859 [=======================>......] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# specify MLP 1 or 2 here\n",
    "\n",
    "estimator = KerasRegressor(build_fn=MLP_B2, epochs=epochs, batch_size=705, verbose=1)\n",
    "\n",
    "# Enter checkpoint filename here\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints'+str(PredictionTimepoints)+'.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "estimator.fit(X_train, y_train,  validation_data=(X_valid, y_valid),callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.122233576878655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = MLP_B2()\n",
    "model.load_weights('saved_models/weights.best.from_scratch_MLPtype2_B2_Timepoints'+str(PredictionTimepoints)+'.hdf5')\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate the Trained networks => Predict Profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Profit for multi company forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale targets and transform them into percentual changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59387861 -1.53886249 -2.87001864 ... -0.96685013  1.07563529\n",
      "  -0.18873029]\n",
      " [ 1.45322426  1.00662208 -1.26984078 ... -0.3254298   1.20663708\n",
      "  -1.4046455 ]\n",
      " [ 0.0895252  -0.49829509  0.84095719 ...  0.0466422   0.33945704\n",
      "  -0.41095863]\n",
      " ...\n",
      " [-0.27374792 -1.15259868 -1.20428793 ... -0.6555513  -1.31459647\n",
      "  -0.99608075]\n",
      " [ 0.13724679 -0.08673138 -0.34190654 ... -1.12700257  0.10335238\n",
      "   0.18142966]\n",
      " [-1.01425269 -0.70408961 -0.53699073 ... -0.70144861 -0.75714214\n",
      "  -0.60915427]]\n"
     ]
    }
   ],
   "source": [
    "y_test_cont = pd.DataFrame(scaler.inverse_transform(TargetCollection),copy=True)\n",
    "y_temp = y_test_cont.copy(deep=True)\n",
    "i=0\n",
    "\n",
    "for entry in TargetCollection:\n",
    "\n",
    "    if (i!=0):\n",
    "        #print(y_test_cont.iloc[i])\n",
    "        y_test_cont.iloc[i] = 100*(y_temp.iloc[i]-y_temp.iloc[i-1])/y_temp.iloc[i-1]\n",
    "    i=i+1\n",
    "\n",
    "y_test_cont=y_test_cont[1:].values\n",
    "print(y_test_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict for y_pred_cont and transform y_pred_cont to percentual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLP_B2()\n",
    "model.load_weights('saved_models/weights.best.from_scratch_MLPtype2_B2.hdf5')\n",
    "#X_test_cont = np.copy(DataCollection[1:,:,:,:]) # For CNN\n",
    "X_test_cont = np.copy(DataCollection[1:,:,:]) #for MLP\n",
    "y_pred_cont = model.predict(X_test_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cont_df = pd.DataFrame(scaler.inverse_transform(y_pred_cont),copy=True)\n",
    "i=0\n",
    "for entry in y_pred_cont:\n",
    "    \n",
    "    #print(y_test_cont.iloc[i])\n",
    "    y_pred_cont_df.iloc[i] = 100*(y_pred_cont_df.iloc[i]-y_temp.iloc[i])/y_temp.iloc[i]\n",
    "    i=i+1\n",
    "y_pred_cont=y_pred_cont_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check predictions (pred) and actual values (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.552027  ,   3.9295766 , -12.547758  , ...,  15.618395  ,\n",
       "          3.9675112 ,   3.2778034 ],\n",
       "       [ 22.970339  ,   5.650481  ,  -9.868374  , ...,  16.86984   ,\n",
       "          3.062637  ,   3.5416272 ],\n",
       "       [ 21.336515  ,   4.685838  ,  -8.626745  , ...,  17.368101  ,\n",
       "          1.995333  ,   5.0779533 ],\n",
       "       ...,\n",
       "       [-29.2116    , -23.76397   ,   5.268413  , ...,  14.041417  ,\n",
       "         -1.9668149 , -32.552734  ],\n",
       "       [-28.979836  , -22.826275  ,   6.608694  , ...,  14.892237  ,\n",
       "         -0.5045602 , -31.84509   ],\n",
       "       [-29.044626  , -22.716316  ,   7.025351  , ...,  16.291838  ,\n",
       "         -0.47290242, -31.943054  ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59387861, -1.53886249, -2.87001864, ..., -0.96685013,\n",
       "         1.07563529, -0.18873029],\n",
       "       [ 1.45322426,  1.00662208, -1.26984078, ..., -0.3254298 ,\n",
       "         1.20663708, -1.4046455 ],\n",
       "       [ 0.0895252 , -0.49829509,  0.84095719, ...,  0.0466422 ,\n",
       "         0.33945704, -0.41095863],\n",
       "       ...,\n",
       "       [-0.27374792, -1.15259868, -1.20428793, ..., -0.6555513 ,\n",
       "        -1.31459647, -0.99608075],\n",
       "       [ 0.13724679, -0.08673138, -0.34190654, ..., -1.12700257,\n",
       "         0.10335238,  0.18142966],\n",
       "       [-1.01425269, -0.70408961, -0.53699073, ..., -0.70144861,\n",
       "        -0.75714214, -0.60915427]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the maximum value in each timestep = 1 , other = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cont_norm = (y_pred_cont == y_pred_cont.max(axis=1)[:,None]).astype(int)\n",
    "\n",
    "y_pred_cont_norm_df = pd.DataFrame(y_pred_cont_norm,copy=True)\n",
    "y_test_cont_df = pd.DataFrame(y_test_cont,copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cont_norm.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate profit: Every day only the maximum predicted positive stock change is used to invest all of startmoney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only profit from test range on\n",
    "y_test_cont_df = y_test_cont_df[862:]\n",
    "y_pred_cont_norm_df = y_pred_cont_norm_df[862:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "profitMulti = []\n",
    "MaxPercentage =[]\n",
    "RandomInvest = []\n",
    "RandomPercentage = []\n",
    "startmoney = 1.0\n",
    "startmoneyrandom = 1.0\n",
    "\n",
    "for row in y_test_cont_df.index:\n",
    "    for column in y_test_cont_df.columns:\n",
    "    \n",
    "        if y_pred_cont_norm_df[column][row] != 0:\n",
    "            startmoney=startmoney+(startmoney*y_test_cont_df[column][row]*y_pred_cont_norm_df[column][row]/100)\n",
    "            profitMulti.append(startmoney)\n",
    "            MaxPercentage.append(y_test_cont_df[column][row]*y_pred_cont_norm_df[column][row])\n",
    "    startmoneyrandom = startmoneyrandom+(startmoneyrandom*y_test_cont_df[randint(0,len(y_test_cont_df.columns)-1)][row]/100)\n",
    "    RandomInvest.append(startmoneyrandom) \n",
    "    RandomPercentage.append(y_test_cont_df[randint(0,len(y_test_cont_df.columns)-1)][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Profit over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e89b103b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(profitMulti)\n",
    "plt.plot(RandomInvest)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Money\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9899545662957006"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profitMulti[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e89b933b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(MaxPercentage)\n",
    "plt.plot(RandomPercentage)\n",
    "plt.ylabel(\"percentual change used for profit\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=145, minmax=(-9.887738268527059, 21.834787209584512), mean=0.5250537191137037, variance=10.384074193162554, skewness=2.1025433360487216, kurtosis=13.556571570192087)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.describe(MaxPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=145, minmax=(-10.450343195662914, 3.5547477703597807), mean=-0.06358522246779004, variance=3.0905931477434843, skewness=-2.421984467017943, kurtosis=11.952536492019485)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.describe(RandomPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e89b912438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(MaxPercentage, bins=50,alpha=0.5)\n",
    "plt.hist(RandomPercentage, bins=50,alpha=0.5)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"percentual change used for profit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
